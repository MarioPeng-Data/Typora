# 1分区表

分区表实际上就是对应一个HDFS文件系统上的独立的文件夹，该文件夹下是该分区所有的数据文件。**Hive中的分区就是分目录**，把一个大的数据集根据业务需要分割成小的数据集。在查询时通过 WHERE 子句中的表达式选择查询所需要的指定的分区，这样的查询效率会提高很多。

## 1.1 分区表的基本操作

（1）引入分区表（需要根据日期对日志进行管理）

```mysql
/user/hive/warehouse/log_partition/20170702/20170702.log
/user/hive/warehouse/log_partition/20170703/20170703.log
/user/hive/warehouse/log_partition/20170704/20170704.log
```

（2）创建分区表语法

```mysql
create table dept_partition(id int, name string, address string)
partitioned by (month string)
row format delimited fields terminated by '\t';
```

注意：分区字段不能是表中已经存在的数据，可以将分区字段看作表的伪列。

（3）加载数据到分区表中

```
load data inpath '/mario/hive/dept_partition/dept.txt' into table dept_partition partition(month='201709');
load data inpath '/mario/hive/dept_partition/dept.txt' into table dept_partition partition(month='201708');
load data inpath '/mario/hive/dept_partition/dept.txt' into table dept_partition partition(month='201707');
```

注意：分区表加载数据时，必须指定分区

![image-20210714222524207](https://gitee.com/peng-bo19951013/Picture/raw/master/20210715000323.png)

（4）查询分区表中数据

单分区查询

```mysql
select * from dept_partition where month='201709';
```

多分区联合查询

```mysql
select * from dept_partition where month='201709' union
select * from dept_partition where month='201708'union
select * from dept_partition where month='201707';
```

![image-20210714223734361](https://gitee.com/peng-bo19951013/Picture/raw/master/20210715000311.png)

（5）增加分区

创建单个分区

```mysql
alter table dept_partition add partition(month='201706') ;
```

同时创建多个分区

```mysql
alter table dept_partition add partition(month='201705') partition(month='201704');
```

（6）删除分区

删除单个分区

```
alter table dept_partition drop partition (month='201704');
```

同时删除多个分区

```
alter table dept_partition drop partition (month='201705'), partition (month='201706');
```

（7）查看分区表有多少分区

```
show partitions dept_partition;
```

（8）查看分区表结构

```
desc formatted dept_partition;
```

## 1.2分区表注意事项

（1）创建二级分区表

```mysql
create table dept_partition2(deptno int, dname string, loc string) 
partitioned by (month string, day string) 
row format delimited fields terminated by '\t';
```

（2）正常的加载数据

加载数据到二级分区表中

```mysql
load data inpath '/mario/hive/dept_partition/dept.txt' into table
dept_partition2 partition(month='201709', day='13');
```

查询分区数据

```mysql
select * from dept_partition2 where month='201709' and day='13';
```

（3）把数据直接上传到分区目录上，让分区表和数据产生关联的三种方式

方式一:上传数据后修复

- 上传数据

```mysql
hdfs dfs -mkdir -p /user/hive/warehouse/dept_partition2/month=201709/day=12;
hdfs dfs -put /opt/module/datas/dept.txt  /user/hive/warehouse/dept_partition2/month=201709/day=12;
```

- 查询数据（查询不到刚上传的数据）

```mysql
select * from dept_partition2 where month='201709' and day='12';
```

- 执行修复命令

```mysql
msck repair table dept_partition2;
```

- 再次查询数据

```mysql
select * from dept_partition2 where month='201709' and day='12';
```

方式二：上传数据后添加分区

- 上传数据

```
hdfs dfs -mkdir -p /user/hive/warehouse/dept_partition2/month=201709/day=11;
hdfs dfs -put /opt/module/datas/dept.txt  /user/hive/warehouse/dept_partition2/month=201709/day=11;
```

- 执行添加分区

```mysql
alter table dept_partition2 add partition(month='201709', day='11');
```

- 查询数据

```mysql
select * from dept_partition2 where month='201709' and day='11';
```

方式三：创建文件夹后load数据到分区

- 创建目录

```mysql
hdfs dfs -mkdir -p  /user/hive/warehouse/dept_partition2/month=201709/day=10;
```

- 上传数据

```mysql
load data inpath '/mario/hive/dept_partition/dept.txt' into table dept_partition2 partition(month='201709',day='10');
```

- 查询数据

```mysql
select * from dept_partition2 where month='201709' and day='10';
```

